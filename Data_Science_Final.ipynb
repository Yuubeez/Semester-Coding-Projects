{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08042349-5d74-4c33-b8ea-42e08e6063f0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Section 1: Data and research questions\n",
    "This study was obtained from Hesselbach and Scheiner (2018) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5862975/\n",
    "\n",
    "The study was performed to see if exposure of a pesticide called Sivanto containing a chemical called flupyradifurone (Launched by a European company) affects the way forager honeybee's \n",
    "can taste and if it influences their cognition negatively. In order to perform this experiment, the authors of this paper gathered information on each bees daily: \n",
    "For each bee: They took information on what type of forager bee is was, the Bee ID, what time of the day tests and data were collected, the treatment they recieved, and how bees reacted to each specific test. \n",
    "\n",
    "<strong>Observations:</strong> The observations of this study is each bee. A total of 426 observations were taken and these observations were obtained from a colony located at Wurzburg University. Returning forager bees were caught in a glass jar at the entrance of the beehive. \n",
    "\n",
    "<strong>Features:</strong> The features of this study describes the information on what type of treatment a bee received at a specific time and day. There are 39 features. It describes what type of  treatment they received, what bee group they are in, how the bees performed due to a specified treatment, specified detail on each test such as dose concentration and the overall results of each test. Features were gathered by performing the tests and recording the performance of each bee. \n",
    "    \n",
    "This study specifically used a pesticide containing <strong>Flupyradifurone</strong> because it was found that another chemical called <strong><em>Neonicotinoids</em></strong> was restricted by the Eurpoean union because this chemical can bind to a <em>nicotinic acetylcholine receptor</em> (nAchR) in a honeybees brain. Flupyradifurone has an active ingredient that can similarly bind to this nAchR receptor in bees. Using this outside knowledge, they specifically wanted to test if this chemical can have an affect on the cognitive function and taste of bees since these functions are all controlled by the brain. \n",
    "        \n",
    "   >The data relates to the research question because they are testing to see if exposure to this chemical can cause foraging problems for honeybees. From observing the data that was \n",
    "        obtained, they can to see how flupyradifurone exposure based on concentration can affect their taste and cognitive functions. Using this data, they would be able to find out if this chemical\n",
    "        is safe to use without endangering the health of bees. \n",
    "            Another research question that can be asked using this data is would this chemical affect a specific group of forager bee more compared to the other? In this case does a pollen forager bee\n",
    "        have a better resistance to flupyradifurone compared to the nectar foragers? The data used in this study worked with forager honeybees, but they included two different classes of them, pollen \n",
    "        and nectar. We can use the data to compare and analyze the results of the tests between the two classes of bees to see if this chemical affects one group more than the other, or if one group\n",
    "        performs better than the other even with the same flupyradifurone exposure. \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17cd49-0b19-4a82-af07-be3c0909db4f",
   "metadata": {},
   "source": [
    "## Section 2: Visualizations and data summaries\n",
    "\n",
    "![image.png](https://cdn.discordapp.com/attachments/201133886175051777/1026945778188566538/unknown.png)\n",
    "### Figure 1: From Hesselbach and Scheiner(Figure 1.) 2019\n",
    "This figure shows the overall proboscis(taste) response of both pollen and nectar forager bees, when they were exposed to different concentrations of Flupyradifurone.\n",
    "\n",
    "In this figure, there are a total of 4 different graphs. There are two line graphs at the top and two box plots at the bottom. All the graphs to the left in figure 1 represent the results of the response \n",
    "test from Pollen foragers, and all the graphs to the right show the results of the tests from Nectar foragers. In both line graphs, they contain a y-axis that represents the percent amount of bees that \n",
    "responded to an external stimulus. Then in the X-axis it shows the sugar concentration in which the bees were exposed to. Each individual data point on the graph is showing the percentage of bees that \n",
    "responded to a sugar stimulus at a specific concentration. Each graph also has four different colored lines, with each line representing different treatment groups. The green dotted line represents the \n",
    "control group, the blue line, purple and red line are groups who were treated with Flupyradifurone(8.3*10^-6, 8.3*10^-5 and 8.3*10^-4 mol/l) respectively. \n",
    "\n",
    "In both box plots, they contained a y-axis called GRS, which is short for Gustatory Responsiveness, this represents the taste response of bees to sugar. On the x-axis it shows the amount of \n",
    "flupyradifurone(mol/l)that was exposed to the bees. Similar to the line graph, each color represents different groups of bees based on how much flupyradifurone they were exposed to. \n",
    "\n",
    "The authors Hesselbach and Scheiner included this figure in the study because it can show if exposure to high amounts of flupyradifurone can have a large impact on how bees detect sugar. The figure shows that the new pesticide Sivanto can have harmful properties to honeybees if the bees consumed too much of this pesticide. From this figure, we can conclude that the active ingredient in flupyradifurone can make bees react negatively and affect their sense of taste. However, small exposure of this chemical will not cause too much harm on the bees.\n",
    "\n",
    "![image.png](https://cdn.discordapp.com/attachments/201133886175051777/1026945508398338098/unknown.png)\n",
    "### Figure 2: From Hesselbach and Scheiner(Figure 2.) 2019\n",
    "The figure above shows the results of a conditioned proboscis and taste response, as well as the aquisition score.\n",
    "\n",
    "In this figure, similarly to the figure 1, it has two line graphs and two box plots. The graphs containing information on the Pollen foragers are located on the left side, whereas the Nectar foragers are located on the right. The line graphs at the top has a y-axis that shows the percent of bees that had a conditioned proboscis response, and it has an x-axis showing the trial number. Each individual data point represents the amount of bees that had a conditioned proboscis response to an external stimulus. Each color on the graph represents different treatment groups, with the green representing the control group. Then the blue, purple and red lines represents the groups who were treated with flupyradifurone(8.3*10^-6, 8.3*10^-5 and 8.3*10^-4 mol/l) respectively. \n",
    "\n",
    "The two box plots at the bottom contain a y-axis showing the aquisition score. This score is the sum of the conditioned response per bee during the conditioned trials. The x-axis shows the amount of flupyradifurone that was exposed to the bees. Just like the box plot in figure 1, each color on the graph represents different groups of bees based on the concentration of flupyradifurone(mol/l) they were exposed to. \n",
    "\n",
    "The authors included this figure in the study because it shows how well the bees cognitive response is. It contributes to the overall arguments of the paper because it can show if a large dose of flupyradifurone can affect how their memory works. From this figure, we can conclude that the bees who have been exposed to a high concentration of flupyradifurone have an impact on cognitive function. However, little exposure to this chemical will not affect their cognitive function drastically.\n",
    "\n",
    "### Another table I would create\n",
    "One other table I would include to help better understand this data is to create a table that can show the performance of each forager bee group (pollen or nectar forager) and how well they did for each test based on how much flupyradifurone they were exposed to. The index of the table would be the dose concentration of flupyradifurone. Then the first column would contain the type of forager bee it was. The next column after this one would contain the average GRS score obtained by the bees based on their exposure, then the next column would contain the average E-Score of bees. This can help us see the overall performace of the bees based on their exposure to the chemical, and it can also let us see if a certain bee group had a higher resistance to this chemical. This can help us determine if this chemical does indeed affect their cognitive abilites and taste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c162226-217c-4536-926c-6c2d58886d34",
   "metadata": {},
   "source": [
    "## Section 3: Describing Data\n",
    "There are 426 rows and 39 columns in the supplementry data contained in one of the tabs within the excel file for this study. The data within this file relates to the data in the paper because it shows results of each experiment that was performed in detail. For each bee, it contains the type of treatment they received and which foraging group they belonged into. With a deeper analysis of this data, it would be possible to see and compare how the effects of Flupyradifurone affects how well bees performed in terms of cognitive(memory) function and taste.\n",
    "\n",
    "For the column that was named \"Treatment Code\" there were delimiters such as a comma, to separate different conditional statements within each cell. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e2aaf-4746-4dbf-a88f-792795f95410",
   "metadata": {},
   "source": [
    "## Part 2: Clean and Describe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d1230-ac49-4374-9b2f-08611f118c21",
   "metadata": {},
   "source": [
    "### Section 1: Load and Clean Data\n",
    "\n",
    "Data can be obtained from the original paper by Hesselbach and Scheiner (2018) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5862975/.\n",
    "\n",
    "Once the link has loaded, there is a section called **Associated Data** and right under it, there are two drop down options: **Supplementary Materials** and **Data Availability Statement**. Click on the **Supplementary Materials** drop down menu and there should be two excel files. Select **Supplementary Dataset 1** to download the excel file.\n",
    "\n",
    "Once the excel file is downloaded, the first page that you will see is called Supplementary Dataset with the title of the article and the author. There are 4 different tabs at the bottom of the excel sheet including the current one you are in. You should currently be in the tab called **Tabelle1** and there are three other tabs called **Data_Honeybees**, **Data_mortaility**, and **Data_preliminary_mortality**. We only want the data from **Data_Honeybees**. Please click on the **Data_Honeybees** tab and save it (A popup will show up when you try to save in the **Data_Honeybees** tab, please click \"OK\") as a csv file called forager_bee in the **downloads directory**. This will be the main directory we will be using to load in our data.\n",
    "\n",
    "There is a small change that needs to be made in order to make it easier to organize our data. There is a column called **ID** and we need to re-number the ID's in numerical order. \n",
    "\n",
    "The scientists of this paper decided to start with 1 everytime they started to take data at a different date or time. Each ID is used to represent a unique bee and due to the way they identified them, it can cause two different bee data to be mixed together due to them having the same ID even though they are two completely different bees. To make things less confusing we will be re-numbering them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25788999-82f1-42b8-8a19-2e1c9877e7d6",
   "metadata": {},
   "source": [
    "### **Important :** Make sure that the *forager_bee* file is saved in the **downloads** directory and your main directory is set as **Downloads**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f877c-0e1a-4c97-9f90-6483843da47b",
   "metadata": {},
   "source": [
    "#### Coding/loading the data in JupyterLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99572d07-b2d6-4c67-9b38-6a8583f8a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>treatment</th>\n",
       "      <th>treatment code</th>\n",
       "      <th>group</th>\n",
       "      <th>H2O</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>E7: Nonanol</th>\n",
       "      <th>E8: Hexanol</th>\n",
       "      <th>E9: Hexanol</th>\n",
       "      <th>E10: Nonanol</th>\n",
       "      <th>E-Score</th>\n",
       "      <th>E-Score Hex.</th>\n",
       "      <th>E-Score Non.</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/6/2017</td>\n",
       "      <td>11.40 Uhr</td>\n",
       "      <td>K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/6/2017</td>\n",
       "      <td>11.40 Uhr</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2017</td>\n",
       "      <td>11.40 Uhr</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/6/2017</td>\n",
       "      <td>11.40 Uhr</td>\n",
       "      <td>K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/6/2017</td>\n",
       "      <td>11.40 Uhr</td>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       time treatment  treatment code  group  H2O  0.1  0.3    1  \\\n",
       "id                                                                             \n",
       "1   6/6/2017  11.40 Uhr         K             0.0    2.0  0.0  0.0  0.0  0.0   \n",
       "2   6/6/2017  11.40 Uhr         B             1.0    2.0  0.0  0.0  0.0  0.0   \n",
       "3   6/6/2017  11.40 Uhr         C             2.0    2.0  0.0  0.0  0.0  0.0   \n",
       "4   6/6/2017  11.40 Uhr         K             0.0    2.0  0.0  0.0  0.0  1.0   \n",
       "5   6/6/2017  11.40 Uhr         D             3.0    2.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      3  ...  E7: Nonanol  E8: Hexanol  E9: Hexanol  E10: Nonanol  E-Score  \\\n",
       "id       ...                                                                 \n",
       "1   1.0  ...          NaN          NaN          NaN           NaN      NaN   \n",
       "2   0.0  ...          0.0          0.0          0.0           0.0      0.0   \n",
       "3   0.0  ...          0.0          1.0          1.0           0.0      7.0   \n",
       "4   1.0  ...          NaN          NaN          NaN           NaN      NaN   \n",
       "5   0.0  ...          NaN          NaN          NaN           NaN      NaN   \n",
       "\n",
       "    E-Score Hex.  E-Score Non.  Unnamed: 36  Unnamed: 37  Unnamed: 38  \n",
       "id                                                                     \n",
       "1            NaN           NaN          NaN          NaN          NaN  \n",
       "2            0.0           0.0          NaN          NaN          NaN  \n",
       "3            5.0           2.0          NaN          NaN          NaN  \n",
       "4            NaN           NaN          NaN          NaN          NaN  \n",
       "5            NaN           NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this part of the code we import our panda package\n",
    "import pandas as pd\n",
    "# This part of the code we load in our forager_bee csv in from our DOWNLOADS directory. We then separate the csv file by comma delimiters and skip the \n",
    "# first 4 rows because we don't need the first four rows of information. We then store it into a variable called forager_bee\n",
    "forager_bee = pd.read_table(\"forager_bee.csv\", sep = \",\",skiprows = 4)\n",
    "# For this part of the code we remove rows in the dataframe that contain a null value in the ID. This new dataframe is stored into the forager_bee\n",
    "# variable once again\n",
    "forager_bee = forager_bee[~forager_bee['id'].isnull()]\n",
    "# create a new variable called count and set it to 1\n",
    "count = 1\n",
    "# create a empty list called id_list\n",
    "id_list = []\n",
    "# This part of the code creates a for loop that basically generates 426 values from 1-426 and stores it into our list called id_list\n",
    "for x in range(len(forager_bee)):\n",
    "    count = x + 1\n",
    "    id_list.append(count)\n",
    "# For this part of the code we assign our id column to now contain the new values we stored in our id_list. This new dataframe is stored into our\n",
    "# variable called forager_bee\n",
    "forager_bee = forager_bee.assign(id = id_list)\n",
    "# For this part of the code we drop the last column of the dataframe because it contains irrelevant information (just comments). This new information \n",
    "# is stored into our forager_bee variable to override the information stored previously\n",
    "forager_bee = forager_bee.iloc[:, :-1]\n",
    "# For this part of the code we set our id as the index\n",
    "forager_bee.set_index(\"id\", inplace = True)\n",
    "# For this part of the code we print out the first 5 rows of our dataframe\n",
    "forager_bee.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4a26a-03aa-410a-bd97-7cdbadc9d900",
   "metadata": {},
   "source": [
    "### Section 2: Describe data numerically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c06fe4-f31c-4d2d-b499-1fcd0c7255e4",
   "metadata": {},
   "source": [
    "#### Looking at the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e858f5f-e17f-4b2e-81d4-80e86dd86ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 38)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forager_bee.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6768b-eb84-45f1-85d0-462784072c7a",
   "metadata": {},
   "source": [
    "To look at the shape of the dataset, we need to run the command **.shape** with the variable in which we stored our dataframe in called **forager_bee**. Shape is used to look at the dimensions of the dataframe (i.e how many different rows and columns there are).\n",
    "\n",
    "The output of the code relates to the number of observations and features because the number **426** shows how many bees were obtained for testing. Then the **38** relates to the information that was found and taken for each bee.\n",
    "\n",
    "The observations matches up with the same amount of observations mentioned in the first part of the project, however the columns is different because when we were cleaning the data, the last row was removed as we didn't need that column (so instead of 39 features we now have 38). It was not a column that was very important or contributed to the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2441455-214b-4374-b1a4-e888038fec4e",
   "metadata": {},
   "source": [
    "#### Picking two features: GRS score and K-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa941b7-8d41-4918-ab38-0f9493d00cad",
   "metadata": {},
   "source": [
    "**Feature 1: GRS Score - Experimental group 3**\n",
    "\n",
    "If the describe code was used I would expect to get numerical data showing the overall summary of that specific column such as how many observations (counts) there are in the column. For example this specific feature is used to describe the overall results of how well each bee performed for the \"taste\" test. More specifically for this column, I would like to look at how well the bees in experimental group 3 performed for this test. I expect the count to be the total amount of bees that were in this group, which is 105. Since treatment group 3 is exposed to the lowest concentration of this chemical, I believe the minimum value would be 0 and the maximum would be 7 since it is possible to score a 0 and a maximum of 7. This chemical exposure since it is little, should have little impact on bees, which is why I believe it would be possible to score a perfect score of 7. A score of 0 would be probable as well due to outliers. The describe function also has three different percentiles: 25%, 50% and 75%, this basically tries to split the data (based on the max and min values) into even parameters to let us know what percent of values from are dataset are below that number. Since we have a max of 7 (based on the maximum GRS score that a bee could score in this experimental group), splitting this number without decimals would be about 3 for 25%, 5 for 50% and 7 for 75%. For the mean of this data, I predict it to be around 4-5 based on the overall GRS score of the bees in experimental group 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d430a6ea-a3aa-4055-8a05-aef863579f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    105.000000\n",
       "mean       4.657143\n",
       "std        2.187502\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        5.000000\n",
       "75%        7.000000\n",
       "max        7.000000\n",
       "Name: GRS, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = forager_bee.loc[:,'treatment code'] ==  3.0\n",
    "GRS_df = forager_bee[count]\n",
    "GRS_df.loc[:,'GRS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8746e47-0d9b-48cf-93c3-083e2cda5033",
   "metadata": {},
   "source": [
    "After running the results, my predictions for all three percentiles were not correct. The actual percentiles for the GRS column among experimental group 3 were 3 for 25%, 5 for 50% and 7 for 75%, which is exactly what I predicted. My predicted mean was about 4-5, and the actual mean was 4.65 , which means that my prediction was within range of the actual mean. Additionally, the min value was predicted correctly with a value of 0, and the maximum value was also predicted correctly with a value of 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9287e3-c79f-4194-a579-ca2b79519249",
   "metadata": {},
   "source": [
    "**Feature 2: E-Score - Experimental group 3**\n",
    "\n",
    "For this specific column, it describes how well the bees performed for the memory test (this is used to test for their cognitive abilities). I would expect the counts to be less compared to the observations, around 80. The reason why this number is lower and not the same number as the observations because some bees from the previous tests were dropped if they did not meet the requirements for this part of the study. For the mean I believe that it would be around 4 because I believe exposure to this chemical could affect their cognitive abilities, which would affect their E-Score, making the overall average low. I expect the minimum value to be 0 and the maximum to be 7 because there are always outliers and bees could always score a value of 0. Additionally I believe the maximum would be 7 because since they were exposed to the lowest dosage of the chemical, it shouldn't be possible to score a perfect score of 10 due to this exposure. However since it is the lowest dosage, their cognitive abilites should not be super affected, so they would still be able to score somewhat high. Then for the percentiles, I believe the 25% would be around 1, the 50% would be around 3 and the 75% would be around 6. These percentiles are based on the maximum and minimum value that I predicted the bees would score for experimental group 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fb9de3-2af4-4a90-8e7b-c912e07972a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      3.160000\n",
       "std       2.636943\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       3.000000\n",
       "75%       5.000000\n",
       "max      10.000000\n",
       "Name: E-Score, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = forager_bee.loc[:,'treatment code'] ==  3.0\n",
    "E_df = forager_bee[count]\n",
    "E_df.loc[:,'E-Score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5b943-79e5-4770-9811-e9049d7553e4",
   "metadata": {},
   "source": [
    "After running the describe command on the E-Score column, my predicted count was different than the expected. I predicted a count to be around 80, but the actual count was 50 so I was 30 off the actual amount. The calculated mean was 3.16, which is 0.84 lower than my predicted value of 4. The minimum matched my predictions but my maximum was 3 off from the actual. As for the percentiles, I predicted the 25th and 75th percentiles incorrectly. The 25th percentile had a value of 0 and the 75th percentile had a value of 5. I was off by 1 for both the 25th and 75th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ded8c5-6966-499a-80c7-923217f75d07",
   "metadata": {},
   "source": [
    "### Section 3: Basic Univariate Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5b544-f885-4546-b644-9e2398a912cf",
   "metadata": {},
   "source": [
    "#### GRS score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b16c3-7b58-438f-b8c7-f964d549e35e",
   "metadata": {},
   "source": [
    "For the GRS score, I believe using a histogram would be helpful to observe this data. I wanted to be able to see the distribution of the GRS score, and the best way to visualize this would be through a histogram. Using this visualization we would be able to interpret how the bees performed based on their exposure to the chemical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3361f4d-5f68-4e14-9e68-3f3fb861b5ea",
   "metadata": {},
   "source": [
    "#### Coding and Explaination of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b51ef17-7273-45cb-bd96-e1b8ff1a4d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x28be1ca9820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part of the code imports our seaborn package as sns\n",
    "import seaborn as sns\n",
    "# This part of the code sets the theme so our graphs looks better\n",
    "sns.set_theme()\n",
    "# For this part of the code we locate the bees who had a treatment code of 3, creating a boolean. This is then stored in a variable called count\n",
    "count = forager_bee.loc[:,'treatment code'] ==  3.0\n",
    "# For this part of the code we index our count boolean back into our forager_bee dataframe so only the rows that met the requirements will show up. This\n",
    "# new dataframe is stored in a variable called GRS_df\n",
    "GRS_df = forager_bee[count]\n",
    "# For this part of the code we plot a histogram of the GRS score from our GRS_df\n",
    "sns.displot(x=\"GRS\", data=GRS_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0c47d-a586-41dd-8823-6c6c26b756fc",
   "metadata": {},
   "source": [
    "#### Interpreting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae5eeb-7e3a-473a-b4d6-2598d0c41f88",
   "metadata": {},
   "source": [
    "When the histogram is compared to the describe function, we can see that the percentiles matches up to the distributions seen in the histogram. Based on the describe function, about 25% of the data is below 3, and if we take a look at the histogram, we can see that the 25th percentile is located around 3, the 50th percentile is located around 5 and the 75th is located around 7.\n",
    "\n",
    "Based on the histogram, the minimum value is 0 and the maxiumum is 7, which matches with the min/max values from the describe function based on the GRS data.\n",
    "\n",
    "The mean of the graph seems to be between 4-5 with the majority of data around 4-5. The mean being 4.65 based on the describe function can be reasonable since most of the data is around 4-5.\n",
    "\n",
    "The graph relates to the hypothesis of the paper because we can see that most bees who have been exposed to this chemical had scores that lingered between 4-5. It shows that this chemical may have an affect on bees in terms of their taste response as a good amount of bees had scores below 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ad63e-dbc2-432a-98ff-7df4712a3fda",
   "metadata": {},
   "source": [
    "#### E-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1293e2e-4347-493a-8e04-d8c76455d1dd",
   "metadata": {},
   "source": [
    "For the E-Score, I also thought it would be good to use a histogram here to see the distribution of the data for bees who had been exposed to Flupyradifurone. Using this data we would be able to see how well the bees had performed after mild exposure to Flupyradifurone in terms of their cognitive function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7635db-9057-496d-a840-2553f570f4ff",
   "metadata": {},
   "source": [
    "#### Coding and Explaination of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d63ef53-afd9-4358-a5ec-3d4826f8b415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x28bdcbf9400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part of the code imports our seaborn package as sns\n",
    "import seaborn as sns\n",
    "# This part of the code sets the theme so our graphs looks better\n",
    "sns.set_theme()\n",
    "# For this part of the code we locate the bees who had a treatment code of 3, creating a boolean. This is then stored in a variable called count\n",
    "count = forager_bee.loc[:,'treatment code'] ==  3.0\n",
    "# For this part of the code we index our count boolean back into our forager_bee dataframe so only the rows that met the requirements will show up. This\n",
    "# new dataframe is stored in a variable called E_df\n",
    "E_df = forager_bee[count]\n",
    "# This part of the code plots a histogram of our E-Score\n",
    "sns.displot(x=\"E-Score\", data=E_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a02cc-9091-4e65-b556-15924af66c33",
   "metadata": {},
   "source": [
    "#### Interpreting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22669d82-907e-4459-aaa5-38bcef0977ec",
   "metadata": {},
   "source": [
    "When comparing the histogram to the describe function, the percentiles matches up between the two. Based on the histogram the 25th percentile is 0, the 50th percentile is around 3 and the 75th percentile is at 5. When we look at the output from the describe function, the values match up. \n",
    "\n",
    "It is hard to actually see where the mean is, but we can safely assume that the mean is between 0 - 4 based on the histogram because the majority of the data is located between 0 - 4. When we look at the mean we can see that the value is 3.16, which is indeed between 0 - 4.\n",
    "\n",
    "We can also see from the histogram that the maximum value is 10 and the minimum is 0. This information matches with the max and min values obtained from the describe command.\n",
    "\n",
    "This histogram relates to the hypothesis from the paper because for the E-Score test, the maximum value that can be obtained is 10. Obtaining a 10 means that the bee had good memory to recognize which scent was associated with sugar. However in this case, most of our data is between 0 - 5, which means that the majority of bees had a score between 0 - 5. This shows that the cognitive function of bees were affected because as we can see, more than half the count of bees had scores below 5. A low score means that they were not able to remember which scent was associated with sugar and showed no response when exposed to those scents. This shows that exposure to Flupyradifurone can have an affect on the cognitive function of bees as the distribution of the bees E-score was on the lower end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392260ce-0514-4bef-976a-18c25d75a5a5",
   "metadata": {},
   "source": [
    "## Part 3: Model Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96389b-26e4-4c2c-9a8c-3f7c60c860d7",
   "metadata": {},
   "source": [
    "### **Question 1:** Were the cognitive function of forager bees affected with a higher exposure to flupyradifurone?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b481e-3655-4976-82c3-38176c62c51f",
   "metadata": {},
   "source": [
    "This question is an interesting concept because it can help determine if this specific pestide is safe to use, and at what exposure level causes it to be harmful towards bees. \n",
    "\n",
    "**Hypothesis**: As the dose concentration of flupyradifurone increases, the cognitive function will be affected more. In other words as the dose concentration increases, the bee's cognitive abilities would decrease.\n",
    "\n",
    "This question relates to the research question because they are trying to determine if this chemical has a harmful affect on bees in order to determine if this chemical is safe to use. One of the effects they were studying was if this chemical affected the bee's cognitive function, and to what degree of exposure to this chemical was safe enough that the bees could still function properly. \n",
    "\n",
    "This data is appropriate to answer this question because we had different groups of bees that were exposed to different concentrations of flupyradifurone. There is also data on the performance of each bee and how well they performed overall for the cognitive function test based on what concentration of flupyradifurone they were exposed to.\n",
    "\n",
    "For the purpose of this question the features I will be using will be the different groups of categorized bees based on their exposure to flupyradifurone (this is marked as the treatment code column in the dataframe), and I will also be using the E-score column. For each group there will be different amount of observations. Treatment code 1 will have 105 observations, treatment code 2 will have 104 observations and treatment code 3 will have 117 observations.\n",
    "\n",
    "<u>**Classification of the different treatment codes:**</u>\n",
    "\n",
    "**Treatment Code 1** = 8.3 * 10-6 (Lowest dose of Flupyradifurone)\n",
    "\n",
    "**Treatment Code 2** = 8.3 * 10-5 (Medium dose of Flupyradifurone)\n",
    "\n",
    "**Treatment Code 3** = 8.3 * 10-4 (Highest dose of Flupyradifurone) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5cc8d1-c7d7-4251-8339-114ac3ff164d",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00042b1e-ac95-4841-8262-7c80579bc8af",
   "metadata": {},
   "source": [
    "For the purpose of this question I will be using a line plot because it can show a continuous change based on what treatment groups the bees are in. In this case we want to see what would happen to the overall E-score of the bees if their exposure to flupyradifurone increased, and a line plot will be able to show what an increased dose would do to the bees. Line plots can give us an overall insight on how the bees performed by looking at the average performance of each treatment group as the dose concentration increased. This would be able to give me an overall insight on the E-Score of bees based on their exposure to flupyradifurone (exposure to flupyradifurone is based on different treatment groups). As mentioned earlier, this visualization (line graph) would be able to give me a good overview of the data since I only want to look at the overall performance (performance meaning how well they scored) of each treatment group. Based on this graph, I expect to see a negative correlation between E-score and flupyradifurone exposure. The results of this graph will be able to address my hypothesis as we will be able to see if an increased dose really does affect the E-score (cognitive abilities) of bees. Lower E-score means that the bee's cognitive abilities are more affected, while a higher E-score shows that the bee's cognitive function was not as affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9d6ee4-0036-4e4d-b114-a66bda1cb0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='treatment_code'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part of the code looks into the treatment code column and finds out which row does not equal to 0. We then boolean index it back into our \n",
    "# dataframe forager_bee to only grab the rows that do not have 0 in treatment code\n",
    "forager_bee_no0 = forager_bee[forager_bee.loc[:,'treatment code'] != 0]\n",
    "# This part of the code groups by treatment code, the finds the mean of all features for each group. This is stored into a variable called group_bee\n",
    "group_bee = forager_bee_no0.groupby('treatment code').mean()\n",
    "# # This part of the code resets the index of our group_bee dataframe so we can access our treatment code column, this new dataframe is stored into a \n",
    "# # variable called reset_bee\n",
    "reset_bee = group_bee.reset_index()\n",
    "# This part of the code locates the column treatment code and stores it in a variable called new_codes\n",
    "new_codes = reset_bee.loc[:,\"treatment code\"] \n",
    "# This part of the code creates a list called new_code_list\n",
    "new_code_list = []\n",
    "# This part of the code creates a for loop, that looks at the treatment code list and re-assigns the treatment codes so that the lowest treatment is\n",
    "# assigned as 1, the medium treatment is assigned as 2 and the highest exposure treatment is assigned to 3. These new values are appended into the\n",
    "# new_code_list.\n",
    "for i in new_codes:\n",
    "    if i == 1.0:\n",
    "        new_code_list.append(3)\n",
    "    elif i == 2.0:\n",
    "        new_code_list.append(2)\n",
    "    else:\n",
    "        new_code_list.append(1)\n",
    "# This part of the code adds this newly re-organized treatment code values into the reset_bee dataframe as treatment_code\n",
    "reset_bee = reset_bee.assign(treatment_code = new_code_list)\n",
    "# # This part of the code creates a line graph, showing the E-score of bees based on their exposure to flupyradifurone\n",
    "reset_bee.plot.line(x = 'treatment_code', y = 'E-Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a55e04-a5ef-4a47-8d1d-ff88e236ec03",
   "metadata": {},
   "source": [
    "Based on the visualization, I would be able to assess my hypothesis because we can see how the bees performed based on their treatment groups. From looking at the visualization I can conclude that there appears to be a relationship between treatment code (also known as different exposure groups) and how well the bees performed in terms of their E-Score. It appears that as the dose concentration increased, their E-score also decreased, signaling a negative relationship between these two variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77347fde-ca73-456d-b5dd-f16d07d8984d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e57a0-29ef-426c-a86e-1c4bc4b36c0f",
   "metadata": {},
   "source": [
    "For my model I will be using the feature treatment code (or also known as flupyradifurone exposure), and I will also be using the E-score. These features will be important for my model because I want to test to confirm if there is indeed a relationship between these two features.\n",
    "\n",
    "There are no other features that are used in the model besides the ones stated above.\n",
    "\n",
    "For the purpose of this question, I will be using a linear model because linear models can show if the E-score of bees depend on the exposure they had to flupyradifurone. This model will be able to show if this chemical has a bad effect on bees in terms of their cognitive function. A bad effect in this case is if the brain function of bees are greatly affected. In other words, if the brain function of bees decreased. Based on my visualization, I expect my slope to be around 1.2 (using the manual rise over run method) and my intercept to be around 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276a9a6b-1e63-4045-a498-2109275bb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>E-Score</td>     <th>  R-squared:         </th> <td>   0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>3.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:27</td>     <th>  Log-Likelihood:    </th> <td> -358.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th> <td>   720.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   154</td>      <th>  BIC:               </th> <td>   726.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_code</th> <td>   -1.0401</td> <td>    0.246</td> <td>   -4.235</td> <td> 0.000</td> <td>   -1.525</td> <td>   -0.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>    4.4512</td> <td>    0.524</td> <td>    8.502</td> <td> 0.000</td> <td>    3.417</td> <td>    5.485</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.033</td> <th>  Durbin-Watson:     </th> <td>   1.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>  10.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.642</td> <th>  Prob(JB):          </th> <td> 0.00450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.890</td> <th>  Cond. No.          </th> <td>    6.89</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                E-Score   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.099\n",
       "Method:                 Least Squares   F-statistic:                     17.94\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):           3.91e-05\n",
       "Time:                        15:44:27   Log-Likelihood:                -358.08\n",
       "No. Observations:                 156   AIC:                             720.2\n",
       "Df Residuals:                     154   BIC:                             726.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "treatment_code    -1.0401      0.246     -4.235      0.000      -1.525      -0.555\n",
       "const              4.4512      0.524      8.502      0.000       3.417       5.485\n",
       "==============================================================================\n",
       "Omnibus:                       10.033   Durbin-Watson:                   1.757\n",
       "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.808\n",
       "Skew:                           0.642   Prob(JB):                      0.00450\n",
       "Kurtosis:                       2.890   Cond. No.                         6.89\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code imports our statsmodel package\n",
    "import statsmodels.api as sm\n",
    "# This part of the code creates a empty list called new_code_list\n",
    "new_code_list = []\n",
    "# This part of the code grabs the treatment code column in our dataframe forager_bee_no0\n",
    "new_codes = forager_bee_no0.loc[:,\"treatment code\"] \n",
    "# This part of the code creates a for loop, that looks at the treatment code list and re-assigns the treatment codes so that the lowest treatment is\n",
    "# assigned as 1, the medium treatment is assigned as 2 and the highest exposure treatment is assigned to 3. These new values are appended into the\n",
    "# new_code_list.\n",
    "for i in new_codes:\n",
    "    if i == 1.0:\n",
    "        new_code_list.append(3)\n",
    "    elif i == 2.0:\n",
    "        new_code_list.append(2)\n",
    "    else:\n",
    "        new_code_list.append(1)\n",
    "# This part of the code adds this newly re-organized treatment code values into the forager_bee_no0 dataframe as treatment_code\n",
    "forager_bee_no0 = forager_bee_no0.assign(treatment_code = new_code_list)\n",
    "# This part of the code sets our treatment code column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if treatment code was seen as a string.\n",
    "bee_marker = (forager_bee_no0['treatment_code']).astype(int)\n",
    "# This part of the code creates a new dataframe with our E-score and the Treatment_code. This new dataframe is stored into a variable called to_model\n",
    "to_model = pd.DataFrame({\"E-Score\":forager_bee_no0['E-Score'],\n",
    "                         \"treatment_code\": bee_marker})\n",
    "\n",
    "# This part of the code removes any null values from the E-score column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['E-Score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the E-score column of our dataframe to_model into the variable y\n",
    "y = to_model[\"E-Score\"]\n",
    "# This part of the code sets the treatment code, and const column of our dataframe to_model into the variable X\n",
    "X = to_model.loc[:,(\"treatment_code\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker\n",
    "model_marker = sm.OLS(y, X).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96e8f4-0d1f-4aad-8b69-fd20e1d6d1cc",
   "metadata": {},
   "source": [
    "Based on the model we can see that the intercept of the data is 4.4512 and the slope of our model is -1.0401. The intercept tells us the expected mean value of our E-score when our x or treatment group is 0. Since our slope is negative, it means that there is a negative correlation between E-score and our treatment groups. This means that as the treatment code increases (so more exposure to the chemical) the lower the E-Score. If we look into the standard error column, we can see that treatment code has a standard error of 0.246 and const has a standard error of 0.532. This column basically tells us how different our sample mean would be if we were to repeat the study using this model. Based on the data, we can be **certain** about our parameters. If we take a look at the P value for treatment code, we can see it has a value of 0, this means that the results we got is not due to chance. It means that we can be certain about our results as we can reject our null hypothesis since it is under 0.05. The same can be seen for our const where our p-value is 0, meaning that our results are not due to chance. Additionally, when we add and subtract and add our coef column with their respective standard errors, we still get a negative value for slope, and a positive value for const. This further shows that we can be certain that there is a negative relationship between treatment group and E-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db30750-f294-4ebb-85fa-36a1ffbf46ac",
   "metadata": {},
   "source": [
    "Based on our model results, we can conclude that a higher exposure of the chemical made the bees have a lower E-Score, whereas a lower exposure to this chemical allowed the bees to have a higher E-score. This shows that the chemical does have a effect on cognitive function as the bees were exposed to a higher level of flupyradifurone. Basically, this means that as the dose concentration(treatment group) increases, the E-score of our bee group decreases by -1.0401. This means that by changing the treatment code in a increasing order, from 1 to 2 or 2 to 3, it would result in a decrease of E-score of -1.0401. In other words, for each increase in treatment code by 1, the E-score of the bees decrease by -1.0401."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e9651-d3b3-43ae-832e-e29032807106",
   "metadata": {},
   "source": [
    "### **Question 2:** Which type of forager bee had a higher GRS score when they were exposed to the highest concentration of flupyradifurone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb29587-de89-4c34-b6ad-170574e09de6",
   "metadata": {},
   "source": [
    "I wanted to ask this question because I wanted to compare and see which type of forager bee, (pollen or nectar forager bees) had a better resistance to this chemical. It would be interesting to study this question because the results of this question can show me if certain forager bees actually have a higher resistance to this chemical. Having a higher resistance in the case of this reserach question means that the bees would still retain their ability to taste even after high exposure to the chemical flupyradifurone. This is really interesting because I have always generalized that bees, for the most part are somewhat similar. So to be able to see if resistance is different among these bee groups also tells me that there may be a chance that a certain forager bee group may have evolved to become more resistance to harmful chemicals. By seeing the results of this question, it can give me some insight on how the chemical affects each bee group, and it may be possible that this chemical can be safely used in certain areas where there is more of a certain bee that has a higher resistance to this chemical. \n",
    "\n",
    "**Hypothesis:** I hypothesize that nectar foragers performed better under high exposure to this chemical\n",
    "\n",
    "This relates to the research question I came up with because this tests to see which type of forager bee had a better taste response after they were exposed a high concentration of flupyradifurone.\n",
    "\n",
    "This data is appropriate to answer this question because it contains information on the two groups of forager bees, their exposure level to the chemical and how well they performed overall for the taste response test. For the purpose of this question, the features I will be using is the bee group, the treatment code, and the GRS score. For the 1st bee group (nectar foragers) will have 62 observations and the 2nd bee group (pollen foragers) will have 55 observations. The difference in observations is due to some bees not meeting the requirements for this test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac257bc0-1550-4c54-bcf0-cf0898add40e",
   "metadata": {},
   "source": [
    "For the purpose of this question, I will be making a violin plot that compares the distribution of the GRS score for both groups of bees. This plot can give insight/inform my hypothesis because it would make it easier to compare the two groups in terms of how well they did. Based on my hypothesis, I expect to see a higher count of nectar forager bees to have a high GRS score compared to pollen foragers. The results will inform my hypothesis because it can tell me if nectar foragers do indeed perform better when they were exposed to a high concentration of flupyradifurone compared to pollen forager bees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2a258-0edd-4f87-8c1c-154fb5c65534",
   "metadata": {},
   "source": [
    "**For the purpose of this question, we will be using our original treatment code data, and not the new one we used in the previous question.**\n",
    "\n",
    "**Treatment Code 1** = 8.3 * 10-4 (Highest dose of Flupyradifurone)\n",
    "\n",
    "<u>**Classification of the two groups:**</u>\n",
    "\n",
    "**Group 1:** Nectar Foragers\n",
    "\n",
    "**Group 2:** Pollen Foragers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c226d9f-47ca-4fd9-ad07-785b4db557db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x28bdef2aee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part of the code only grabs the rows that have treatment code equalling to 1, we then index it back into our forager_bee dataframe so we have a dataframe that only contains\n",
    "# the rows that have a 1 for its treatment code. We then store this into a variable called treatment_1_df\n",
    "treatment_1_df = forager_bee[forager_bee.loc[:,'treatment code'] == 1]\n",
    "# This part of the code creates a violin graph \n",
    "sns.catplot(data=treatment_1_df, x=\"group\", y= \"GRS\", kind = \"violin\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475d13c-fa87-4971-9447-db84b15614b0",
   "metadata": {},
   "source": [
    "This visualization can help assess my hypothesis because we can see how each bee group performed when they were exposed to the highest concentration of flupyradifurone. Based on the plot, it can be concluded that group 1 has performed better than group 2, which means that nectar foragers (group 1) may have a higher resistance to this chemical, which allowed them to have a higher GRS score. This conclusion was reached by looking at the average score of the violin plot. The average score of a violin plot is based on a small white dot that you can see in the middle black bar of each of the violin plots. By comparing the average score between group 1 and group 2, we can see that group 1 has a higher average of around 1.80 whereas group 2 has a average close to 0. Due to this, I concluded that group 1 performed better than group 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1bc19-4cc8-4563-b01c-9a701283ae76",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d3e28-0bb7-4573-b235-10a14fa9c7c0",
   "metadata": {},
   "source": [
    "For my model I will be creating a linear model using features such as bee group, GRS score and treatment code (also known as the exposure level to flupyradifurone). The way treatment code is used in this model is that I wanted to look at one specific treatment group, rather than every treatment group. So in this case, I only grabbed treatment group 1, which was exposed to the highest concentration of flupyradifurone. These features would be important for my model because it can first help us see if bee group has a affect on GRS score, and once we establish this relationship we can understand if one of the bee group has a higher resistance to this chemical, therefore allowing them to perform better.\n",
    "\n",
    "There are no other features used in this model other than the ones listed above.\n",
    "\n",
    "For the purpose of this question, I intend to make a linear model. A linear model can help us see if being in different bee groups has a relationship to how well a bee performed under harsh chemical conditions. It can help us represent the relationship between two variables. This information can then in turn answer our hypothesis, because we can see if being in group 1 (nectar foragers) did in fact affect the GRS score of bees. Based on my visualization, I expect the slope to be around -1 (based on the manual rise over run method) and the intercept to be around 2 (by eyeballing the visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4122ffa-1419-444a-be76-d566abffb3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>GRS</td>       <th>  R-squared:         </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.05907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.808</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:27</td>     <th>  Log-Likelihood:    </th> <td> -259.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   117</td>      <th>  AIC:               </th> <td>   523.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   115</td>      <th>  BIC:               </th> <td>   529.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group</th> <td>   -0.1012</td> <td>    0.416</td> <td>   -0.243</td> <td> 0.808</td> <td>   -0.926</td> <td>    0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.0205</td> <td>    0.646</td> <td>    3.127</td> <td> 0.002</td> <td>    0.740</td> <td>    3.301</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.830</td> <th>  Durbin-Watson:     </th> <td>   2.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  20.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.027</td> <th>  Prob(JB):          </th> <td>3.45e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.973</td> <th>  Cond. No.          </th> <td>    6.68</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    GRS   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.008\n",
       "Method:                 Least Squares   F-statistic:                   0.05907\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):              0.808\n",
       "Time:                        15:44:27   Log-Likelihood:                -259.74\n",
       "No. Observations:                 117   AIC:                             523.5\n",
       "Df Residuals:                     115   BIC:                             529.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "group         -0.1012      0.416     -0.243      0.808      -0.926       0.723\n",
       "const          2.0205      0.646      3.127      0.002       0.740       3.301\n",
       "==============================================================================\n",
       "Omnibus:                       16.830   Durbin-Watson:                   2.174\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.551\n",
       "Skew:                           1.027   Prob(JB):                     3.45e-05\n",
       "Kurtosis:                       2.973   Cond. No.                         6.68\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code imports our statsmodel package\n",
    "import statsmodels.api as sm\n",
    "# This part of the code sets our group column in our dataframe as a int\n",
    "bee_marker1 = (treatment_1_df['group']).astype(int)\n",
    "# This part of the code creates a new dataframe with GRS and the Treatment code. This new dataframe is stored into a variable called to_model1\n",
    "to_model1 = pd.DataFrame({\"GRS\":treatment_1_df['GRS'],\n",
    "                         \"group\": bee_marker1})\n",
    "\n",
    "# This part of the code removes any null values from the GRS column. This new dataframe is stored into a variable called to_model1 again\n",
    "to_model1 = to_model1[~pd.isnull(to_model1['GRS'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model1. This information is stored into our variable called to_model1.\n",
    "to_model1 = sm.add_constant(to_model1)\n",
    "# This part of the code sets the GRS column of our dataframe to_model1 into the variable Y\n",
    "Y = to_model1[\"GRS\"]\n",
    "# This part of the code sets the group, and const column of our dataframe to_model1, into the variable x\n",
    "x = to_model1.loc[:,(\"group\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker1\n",
    "model_marker1 = sm.OLS(Y, x).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f34cd-9639-409d-bd5c-be7f0982f9fd",
   "metadata": {},
   "source": [
    "Based on the data we can see that our slope is -0.1012 and our intercept is 2.0205. This means that there is a negative correlation between our two features. A negative slope/association basically means that as one variable increases, the other decreases. In this case since our bee group is categorized into groups 1 and 2, as our group number increases, the GRS score decreases. If we look into the standard error column, we can see that group has a standard error of 0.416 and const has a standard error of 0.646. This column basically tells us how different our sample mean would be if we were to repeat the study using this model. Based on our model data, we can be **somewhat certain**, but not fully certain about our parameters. The estimation of the intercept based on the visualization was close to the one from the model, however the intercept was off. This makes me question if -0.1012 is really the true slope of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94460c0e-2a79-4c4d-ae50-954401003b07",
   "metadata": {},
   "source": [
    "Based on the model, we can conclude that there appears to be a correlation between being in a certain bee group and GRS score. Since it was a negative slope, it means that the first group had a higher overall GRS score compared to the second group. Due to the uncertainty, we can't say for sure if this incident is due to chance or not. However, based on our model's negative slope parameter, we can conclude that there is a negative correlation between bee group and GRS score. Due to this, bee group 1 showed that they may have a higher resistance to flupyradifurone allowing them to score higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164653b1-f472-43fe-a23c-8c0d7388a3f1",
   "metadata": {},
   "source": [
    "## Part 4: Model Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693db02-a5c7-49eb-b4c2-515dc93e711b",
   "metadata": {},
   "source": [
    "## <u> Research Question 1 : Were the cognitive function (E-score) of forager bees affected more from exposure to flupyradifurone, or does being in a different bee group affect the E-score more? </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c677fe-fe84-46dd-9a29-356cec0ad059",
   "metadata": {},
   "source": [
    "The feature that I want to use is E-score column which is our target feature. As mentioned before, a linear model would be good to answer this question because linear models can show if the E-score (target feature) of bees depend on another variable, showing a relationship between them. To reiterate, the **target feature** of this model is **E-score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48404ba-f080-4be1-b9b3-111e9a8e8baf",
   "metadata": {},
   "source": [
    "**Hypothesis:** The cognitive function (E-score) of forager bees were affected more from exposure to flupyradifurone compared to being in a different bee group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffa1c8-fa1d-44e7-bd65-bd96ba42dc08",
   "metadata": {},
   "source": [
    "### Model 1: E-Score and Treatment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce29b1-b744-4617-8e3e-1fe69791a806",
   "metadata": {},
   "source": [
    "For the purpose of this question, I wanted to see if the E-score of bees depend on the exposure they had to flupyradifurone. This model will be able to show if this chemical has a bad effect on bees in terms of their cognitive function, which would be able to address my hypothesis. This would allow us to see how big of an effect exposure to flupyradifurone has on the E-score of bees, which can address my hypothesis of which variable had more of an effect on E-score.\n",
    "\n",
    "**Model 1, is the same model I did in part 3 for the first question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0af52c-a747-45d0-b2f9-6a0d3586004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>E-Score</td>     <th>  R-squared:         </th> <td>   0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>3.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:27</td>     <th>  Log-Likelihood:    </th> <td> -358.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th> <td>   720.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   154</td>      <th>  BIC:               </th> <td>   726.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_code</th> <td>   -1.0401</td> <td>    0.246</td> <td>   -4.235</td> <td> 0.000</td> <td>   -1.525</td> <td>   -0.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>    4.4512</td> <td>    0.524</td> <td>    8.502</td> <td> 0.000</td> <td>    3.417</td> <td>    5.485</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.033</td> <th>  Durbin-Watson:     </th> <td>   1.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>  10.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.642</td> <th>  Prob(JB):          </th> <td> 0.00450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.890</td> <th>  Cond. No.          </th> <td>    6.89</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                E-Score   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.099\n",
       "Method:                 Least Squares   F-statistic:                     17.94\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):           3.91e-05\n",
       "Time:                        15:44:27   Log-Likelihood:                -358.08\n",
       "No. Observations:                 156   AIC:                             720.2\n",
       "Df Residuals:                     154   BIC:                             726.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "treatment_code    -1.0401      0.246     -4.235      0.000      -1.525      -0.555\n",
       "const              4.4512      0.524      8.502      0.000       3.417       5.485\n",
       "==============================================================================\n",
       "Omnibus:                       10.033   Durbin-Watson:                   1.757\n",
       "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.808\n",
       "Skew:                           0.642   Prob(JB):                      0.00450\n",
       "Kurtosis:                       2.890   Cond. No.                         6.89\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code imports our statsmodel package\n",
    "import statsmodels.api as sm\n",
    "# This part of the code creates a empty list called new_code_list\n",
    "new_code_list = []\n",
    "# This part of the code grabs the treatment code column in our dataframe forager_bee_no0\n",
    "new_codes = forager_bee_no0.loc[:,\"treatment code\"] \n",
    "# This part of the code creates a for loop, that looks at the treatment code list and re-assigns the treatment codes so that the lowest treatment is\n",
    "# assigned as 1, the medium treatment is assigned as 2 and the highest exposure treatment is assigned to 3. These new values are appended into the\n",
    "# new_code_list.\n",
    "for i in new_codes:\n",
    "    if i == 1.0:\n",
    "        new_code_list.append(3)\n",
    "    elif i == 2.0:\n",
    "        new_code_list.append(2)\n",
    "    else:\n",
    "        new_code_list.append(1)\n",
    "# This part of the code adds this newly re-organized treatment code values into the forager_bee_no0 dataframe as treatment_code\n",
    "forager_bee_no0 = forager_bee_no0.assign(treatment_code = new_code_list)\n",
    "# This part of the code sets our treatment code column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if treatment code was seen as a string.\n",
    "bee_marker = (forager_bee_no0['treatment_code']).astype(int)\n",
    "# This part of the code creates a new dataframe with our E-score and the Treatment_code. This new dataframe is stored into a variable called to_model\n",
    "to_model = pd.DataFrame({\"E-Score\":forager_bee_no0['E-Score'],\n",
    "                         \"treatment_code\": bee_marker})\n",
    "\n",
    "# This part of the code removes any null values from the E-score column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['E-Score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the E-score column of our dataframe to_model into the variable y\n",
    "y = to_model[\"E-Score\"]\n",
    "# This part of the code sets the treatment code, and const column of our dataframe to_model into the variable X\n",
    "X = to_model.loc[:,(\"treatment_code\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker\n",
    "model_marker = sm.OLS(y, X).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20157723-d854-4962-bf87-92c1ca8792a8",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489e53e-8dd6-4290-96fb-b254b67a86db",
   "metadata": {},
   "source": [
    "Based on the model we can see that the intercept of the data is 4.4512 and the slope of our model is -1.0401. The intercept tells us the expected mean value of our E-score when our x or treatment group is 0. Since our slope is negative, it means that there is a negative correlation between E-score and our treatment groups. This means that as the treatment code increases (so more exposure to the chemical) the lower the E-Score. \n",
    "\n",
    "If we take a look at the P value for treatment code, we can see it has a value of 0, this means that the results we got is not due to chance. It means that we can be certain about our results as we can reject our null hypothesis since it is under 0.05. The null hypothesis basically tells us if the observed value is due to chance. If we are able to reject it, it means that our observed value is not due to chance, and the data we got is accurate. This means that there is a correlation and we can be certain about our parameters. The same can be seen for our intercept (const) where our p-value is 0, meaning that our results are not due to chance. Based on this data, we can be **certain** about our parameters. \n",
    "\n",
    "Additionally if we take a look at our confidence interval 0.975, we have a 97.5% certainty that our value will fall between -1.525 and -0.555. This further shows that we can be certain that there is a negative relationship between treatment group and E-score. The same could be said for our intercept, when we take a look at the confidence interval for our intercept, we have two positive numbers, further showing that our intercept is indeed positive. Since the confidence interval of our slope is still negative and the confidence interval of our intercept is positive, we can definitely be **certain** about our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56ad7e-5fef-43f1-af87-0c8e5c286a57",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08e77c-272e-48e7-9301-1bd18ba53281",
   "metadata": {},
   "source": [
    "Based on our model results, we can conclude that a higher exposure of the chemical made the bees have a lower E-Score, whereas a lower exposure to this chemical allowed the bees to have a higher E-score. This shows that the chemical does have a effect on cognitive function as the bees were exposed to a higher level of flupyradifurone. Basically, this means that as the dose concentration(treatment group) increases, the E-score of our bee group decreases by -1.0401. This means that by changing the treatment code in a increasing order, from 1 to 2 or 2 to 3, it would result in a decrease of E-score of -1.0401. In other words, for each increase in treatment code by 1, the E-score of the bees decrease by -1.0401."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876eb0a-0796-4c86-ba53-d6689d3bdf53",
   "metadata": {},
   "source": [
    "### Model 2: E-Score and Bee Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3bc7b-5e2f-4278-af2a-9c03fe0ae802",
   "metadata": {},
   "source": [
    "Fitting this model would be able to inform my hypothesis because we would be able to see if different bee groups has an affect on E-score, which is the score of the bee's cognitive function. This model would be able to show if there is indeed a relationship between the target feature and being in a different bee group in terms of cognitive function. With this information we would also be able to see how much of an affect being in different bee groups affected the E-Score, allowing us to address our hypothesis of which feature had more of an effect on our target feature (e-score). \n",
    "\n",
    "**For the purpose of this model, using bee group would make sense for this model as the experiment categorizes these different types of bees, pollen and nectar forager groups as a number. The experiment categorizes pollen forager into group 1 and nectar forager into group 2. By changing this group number, from group 1 to group 2, we can see the difference in how the bees performed based on what type of bee they are. These groups do not contain the same bees, they are different per group. So by changing our group number (in other words we are also changing our bee type by changing this number) we will be able to see if different types of bee perform better in terms of their E-score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c28e929-6d93-4d4d-be2b-852ca5bf19d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>E-Score</td>     <th>  R-squared:         </th> <td>   0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.0227</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:27</td>     <th>  Log-Likelihood:    </th> <td> -364.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th> <td>   732.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   154</td>      <th>  BIC:               </th> <td>   738.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group</th> <td>    0.9260</td> <td>    0.402</td> <td>    2.302</td> <td> 0.023</td> <td>    0.131</td> <td>    1.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9961</td> <td>    0.638</td> <td>    1.560</td> <td> 0.121</td> <td>   -0.265</td> <td>    2.257</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.755</td> <th>  Durbin-Watson:     </th> <td>   1.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  14.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.739</td> <th>  Prob(JB):          </th> <td>0.000788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.881</td> <th>  Cond. No.          </th> <td>    6.89</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                E-Score   R-squared:                       0.033\n",
       "Model:                            OLS   Adj. R-squared:                  0.027\n",
       "Method:                 Least Squares   F-statistic:                     5.299\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):             0.0227\n",
       "Time:                        15:44:27   Log-Likelihood:                -364.03\n",
       "No. Observations:                 156   AIC:                             732.1\n",
       "Df Residuals:                     154   BIC:                             738.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "group          0.9260      0.402      2.302      0.023       0.131       1.721\n",
       "const          0.9961      0.638      1.560      0.121      -0.265       2.257\n",
       "==============================================================================\n",
       "Omnibus:                       12.755   Durbin-Watson:                   1.796\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.292\n",
       "Skew:                           0.739   Prob(JB):                     0.000788\n",
       "Kurtosis:                       2.881   Cond. No.                         6.89\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code sets our group column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if treatment code was seen as a string.\n",
    "bee_marker = (forager_bee_no0['group']).astype(int)\n",
    "# This part of the code creates a new dataframe with our E-score and the group column. This new dataframe is stored into a variable called to_model\n",
    "to_model = pd.DataFrame({\"E-Score\":forager_bee_no0['E-Score'],\n",
    "                         \"group\": bee_marker})\n",
    "\n",
    "# This part of the code removes any null values from the E-score column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['E-Score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the E-score column of our dataframe to_model into the variable y_score\n",
    "y_score = to_model[\"E-Score\"]\n",
    "# This part of the code sets the group, and const column of our dataframe to_model into the variable X_group\n",
    "X_group = to_model.loc[:,(\"group\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_group\n",
    "model_group = sm.OLS(y_score, X_group).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69562317-344e-459f-b59d-aeab5d4eb5f7",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc313e1e-dfa9-403d-a60e-b6c02459ff12",
   "metadata": {},
   "source": [
    "Based on the results of the model we can see that the slope of the model is 0.9260 and the intercept is 0.9961, showing that there appears to be a positive relationship between E-Score and Bee group. This relationship is determined by looking at the slope value. Since the slope of the model was 0.9260, a positive number, this means there is a positive relationship. \n",
    "\n",
    "To determine the certainty of our parameters, I took a look at the confidence interval. Our slope (group) had both positive numbers in its confidence intervals, that means we can expect our numbers to be between 0.131 and 1.721, both of which are positive numbers. However, if we take a look at the confidence interval of our intercept (const) of our model, we can see that there is a negative number with a positive. Due to our confidence interval having a negative value (-0.265), this means that we can't be certain that our intercept is positive. \n",
    "\n",
    "Additionally, to further check the certainty of our parameters, we can take a look at the p-value of our slope and intercept. Our slope had a p-value of 0.023 and our intercept had a p-value of 0.121. Since the p-value of our slope was 0.023 we can reject our null hypothesis because it is under our alpha value (this value basically determines if we reject or accept our null hypothesis. Learned this in statistics.) 0.05. However, the p-value of our intercept was 0.121, which is greater than 0.05 this means that we cannot reject our null hypothesis. Due to this we **can't be certain** about our parameters based on the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa21489-9fea-4aa6-b1c9-ed3b92060daf",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2936c6-1cc0-4214-a362-a7fa1f548c8f",
   "metadata": {},
   "source": [
    "Based on the results of the model, we can conclude that E-score is affected by different bee groups. In other words, when the bee group increases (bee group increases as changing from group 1 to group 2), the E-score increases by 0.9961. In other words, what is meant by \"when bee group increases\" this is another way of saying when the bee group changes (from pollen (group 1) to nectar (group 2)), as our groups are categorized into numbers as shown in the actual excel file of the experiment. So as the bee group changes (from 1 to 2) the E-score increases by 0.9961, showing that these one type of bee may have a better cognitive abilities compared to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14221b64-9879-4e11-b4da-b6678e6513c9",
   "metadata": {},
   "source": [
    "## **Comparision of the two single variable models using two model metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9285436-9abe-4dc6-9e76-d05e6b0f9373",
   "metadata": {},
   "source": [
    "**Comparison of R-Square Values:**\n",
    "\n",
    "**Model 1:** Has a R-Square value of 0.104\n",
    "\n",
    "**Model 2:** Has a R-Square value of 0.033\n",
    "\n",
    "**Comparison of log-likelihood Values:**\n",
    "\n",
    "**Model 1:** Has a log-likelihood value of -358.08\n",
    "\n",
    "**Model 2:** Has a log-likelihood value of -364.03\n",
    "\n",
    "Upon the comparison of the two model metrics, R-squared values and log-likelihood values, we can see that model 1 is a better predicor of the target feature (E-Score). In the first model metric, having a higher R-square value means it is a better predictor. When we compare the R-square values between the two models, Model 1 had a higher R-squared value of 0.104 compared to model 2 with a R-Square value of 0.033. This shows that Model 1 is better. In the second model metric, having a log-likelihood value that is closer to 0 means it is a better predictor. When we compare the log-likelihood values between the two models, we can see that model 1 has a log-likelihood of -335.08 and model 2 has a log-likelihood value of -364.03 showing that model 1 is a better predictor. After the comparison of the two model metrics, model 1 shows that it is a better predictor for our target feature.  Which supports our hypothesis that E-Score is more affected by exposure to the chemical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb513d-de84-4057-b132-a61096ce366f",
   "metadata": {},
   "source": [
    "# <u>**Two 2+ Feature Variable Models for my first research question**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27fe30-7190-4267-8f10-d3ee96bd8c1e",
   "metadata": {},
   "source": [
    "## **First - 2+ feature variable model**: I am using my target feature E-score, and my two other features are Treatment Code and GRS Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9a057-2363-4450-9e22-bf67907b552e",
   "metadata": {},
   "source": [
    "### Model 1: E-Score and Treatment Code + GRS(Gustatory Responsiveness) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a147ae72-dc71-4cca-97d3-6fc2ee048191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>E-Score</td>     <th>  R-squared:         </th> <td>   0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>0.000111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:27</td>     <th>  Log-Likelihood:    </th> <td> -357.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th> <td>   720.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   153</td>      <th>  BIC:               </th> <td>   729.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment code</th> <td>    0.9940</td> <td>    0.248</td> <td>    4.001</td> <td> 0.000</td> <td>    0.503</td> <td>    1.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRS score</th>      <td>    0.1225</td> <td>    0.105</td> <td>    1.164</td> <td> 0.246</td> <td>   -0.085</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>   -0.1272</td> <td>    0.642</td> <td>   -0.198</td> <td> 0.843</td> <td>   -1.395</td> <td>    1.140</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.940</td> <th>  Durbin-Watson:     </th> <td>   1.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>  10.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.639</td> <th>  Prob(JB):          </th> <td> 0.00471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.868</td> <th>  Cond. No.          </th> <td>    17.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                E-Score   R-squared:                       0.112\n",
       "Model:                            OLS   Adj. R-squared:                  0.101\n",
       "Method:                 Least Squares   F-statistic:                     9.667\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):           0.000111\n",
       "Time:                        15:44:27   Log-Likelihood:                -357.39\n",
       "No. Observations:                 156   AIC:                             720.8\n",
       "Df Residuals:                     153   BIC:                             729.9\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "treatment code     0.9940      0.248      4.001      0.000       0.503       1.485\n",
       "GRS score          0.1225      0.105      1.164      0.246      -0.085       0.330\n",
       "const             -0.1272      0.642     -0.198      0.843      -1.395       1.140\n",
       "==============================================================================\n",
       "Omnibus:                        9.940   Durbin-Watson:                   1.788\n",
       "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.715\n",
       "Skew:                           0.639   Prob(JB):                      0.00471\n",
       "Kurtosis:                       2.868   Cond. No.                         17.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code sets our treatment code column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if treatment code was seen as a string.\n",
    "bee_marker = (forager_bee_no0['treatment code']).astype(int)\n",
    "# This part of the code creates a new dataframe with our E-score,Treatment code and GRS score. This new dataframe is stored into a variable called \n",
    "# to_model\n",
    "to_model = pd.DataFrame({\"E-Score\":forager_bee_no0['E-Score'],\n",
    "                         \"treatment code\": bee_marker,\n",
    "                        \"GRS score\": forager_bee_no0['GRS']})\n",
    "\n",
    "# This part of the code removes any null values from the E-score column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['E-Score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the E-score column of our dataframe to_model into the variable y\n",
    "y = to_model[\"E-Score\"]\n",
    "# This part of the code sets the treatment code, GRS score, and the const column of our dataframe to_model into the variable X\n",
    "X = to_model.loc[:,(\"treatment code\",\"GRS score\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker\n",
    "model_marker = sm.OLS(y, X).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9f322-1569-4afe-9c56-70f3339f31a4",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51402d1-730b-4b05-b993-fe1df861105f",
   "metadata": {},
   "source": [
    "After creating our model with two features, we can se that the slope of our model is 0.9940 and 0.1225, with a intercept of -0.1272. This means that there is a positive correlation between E-score, and treatment code + GRS score.\n",
    "\n",
    "To check the certainty of our parameters, we can take a look at the confidence intervals of our parameters. When we take a look at the first slope, (treatment code) the confidence intervals all fall between a positive value, but our second slope (GRS score) had a negative and positive value in its confidence interval. The same can be seen in the confidence interval for our intercept that there is both a positive and negative number. Due to this we can't be certain about our parameters for our second slope and our intercept. \n",
    "\n",
    "However to further test this certainty, we can take a look at the p-value of our parameters. The p-value of our 1st slope (treatment code) was 0, the p-value of our 2nd slope (GRS) score was 0.246 and the p-value of our intercept was 0.843. Due to these high p-values for our 2nd and 3rd parameters, we fail to reject our null hypothesis making our parameters uncertain. Due to the p-value test failing, overall, we **can't be certain** that there is a positive relationship between the E-score and GRS score along with the treatment code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60366a1-3a93-412a-b193-2232c0fa8069",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af3bd7-d48a-44e5-8019-33c5ff43e0e9",
   "metadata": {},
   "source": [
    "Based on the results of our model, we can conclude that GRS score and Treatment code does affect the E-score of bees, however, treatment code appears to have a stronger relationship to E-Score compared to the GRS score. In other words, when the treatment code increases, the E-score increases by 0.9940 and when the GRS score increases, the E-score increases by 0.1225. We can see that the E-score increases less for the GRS score compared to the treatment code. Showing that treatment code has a stronger relationship to our target feature, and that the **GRS score feature is not significant**. \n",
    "\n",
    "Additionally, since the p-value of our slope (GRS) is greater than 0.05 it further shows that our **GRS slope is insignificant**, meaning that the data we obtained from this model doesn't really show that GRS score has an significant effect on E-score. However, when we take a look at the p-value for our slope (treatment code), we can see that it has a p-value of 0. This means that **treatment code is a significant variable**, in other words it is a variable that has a visible effect on E-score.\n",
    "\n",
    "This further addresses our research question that flupyradifurone exposure (treatment group) does have an effect on E-score, however our GRS score may not have a big impact or significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bc326-68a0-49f8-913e-b2a4a0afb85c",
   "metadata": {},
   "source": [
    "## **Second - 2+ feature variable model**: I am using my target feature E-score, and my two other features are Bee group and GRS score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00994837-8da2-4025-bda6-3cf98e5433b8",
   "metadata": {},
   "source": [
    "### Model 2: E-Score and Bee Group + GRS(Gustatory Responsiveness) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185bf8d6-7b51-4772-bf11-d15a3e5d2986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>E-Score</td>     <th>  R-squared:         </th> <td>   0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.0231</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:28</td>     <th>  Log-Likelihood:    </th> <td> -362.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th> <td>   731.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   153</td>      <th>  BIC:               </th> <td>   740.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group</th> <td>    0.8648</td> <td>    0.402</td> <td>    2.149</td> <td> 0.033</td> <td>    0.070</td> <td>    1.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GRS</th>   <td>    0.1667</td> <td>    0.108</td> <td>    1.542</td> <td> 0.125</td> <td>   -0.047</td> <td>    0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3928</td> <td>    0.746</td> <td>    0.526</td> <td> 0.599</td> <td>   -1.082</td> <td>    1.867</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.626</td> <th>  Durbin-Watson:     </th> <td>   1.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  12.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.699</td> <th>  Prob(JB):          </th> <td> 0.00163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.855</td> <th>  Cond. No.          </th> <td>    19.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                E-Score   R-squared:                       0.048\n",
       "Model:                            OLS   Adj. R-squared:                  0.036\n",
       "Method:                 Least Squares   F-statistic:                     3.862\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):             0.0231\n",
       "Time:                        15:44:28   Log-Likelihood:                -362.83\n",
       "No. Observations:                 156   AIC:                             731.7\n",
       "Df Residuals:                     153   BIC:                             740.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "group          0.8648      0.402      2.149      0.033       0.070       1.660\n",
       "GRS            0.1667      0.108      1.542      0.125      -0.047       0.380\n",
       "const          0.3928      0.746      0.526      0.599      -1.082       1.867\n",
       "==============================================================================\n",
       "Omnibus:                       11.626   Durbin-Watson:                   1.844\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.842\n",
       "Skew:                           0.699   Prob(JB):                      0.00163\n",
       "Kurtosis:                       2.855   Cond. No.                         19.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code imports our statsmodel package\n",
    "import statsmodels.api as sm\n",
    "# This part of the code sets our group column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if group column was seen as a string.\n",
    "bee_marker = (forager_bee_no0['group']).astype(int)\n",
    "# This part of the code creates a new dataframe with our E-score, the group column and GRS score. This new dataframe is stored into a variable called \n",
    "# to_model\n",
    "to_model = pd.DataFrame({\"E-Score\":forager_bee_no0['E-Score'],\n",
    "                         \"group\": bee_marker,\n",
    "                        \"GRS\": forager_bee_no0['GRS']})\n",
    "\n",
    "# This part of the code removes any null values from the E-score column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['E-Score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the E-score column of our dataframe to_model into the variable y_score\n",
    "y_score = to_model[\"E-Score\"]\n",
    "# This part of the code sets the group, GRS and const column of our dataframe to_model into the variable X_group\n",
    "X_group = to_model.loc[:,(\"group\",\"GRS\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_group\n",
    "model_group = sm.OLS(y_score, X_group).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ddac2-038e-4daf-b11e-dc39866e9f97",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fc00e-3a7c-4e17-af9b-35cc813cc290",
   "metadata": {},
   "source": [
    "Based on the results of the model, we can see that we have two positive slopes, 0.8648 and 0.1667 with a intercept of 0.3928. Since it is a positive slope it shows that there is a positive relationship between E-score and bee group as well as the GRS score. \n",
    "\n",
    "Similar to the previous model, to test the certainty of this relationship/parameter I decided to look at the confidence interval of our parameters. The confidence interval of our first slope are both positive numbers, however similar to our last model, both our 2nd slope and the intercept contains a positive and a negative number in its confidence interval. Due to this we **can't be certain** that all our parameters have a positive relationship to E-score. \n",
    "\n",
    "However, once again, to further test the certainty of our parameters, we can take a look at the p-value. The p-value of our first slope (group) was 0.033, the p-value of our second slope (GRS) was 0.125 and the p-value of our intercept was 0.599. Since two of our parameters, the second slope and our intercept had a high p-value over 0.05, we cannot be certain of our parameters. Due to the second certainty test giving us mixed results, we **can't be certain** about our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574d84b-42b5-4468-99ed-e9aaae0ebd3e",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57d3b0-43c0-4f64-9c07-69789809715a",
   "metadata": {},
   "source": [
    "Based on the results of the model, we can conclude that Bee group and GRS score does have an effect on E-score of bees. However we can see that, there is a stronger relationship between different bee group (bee type) on E-score compared to the GRS score, meaning that **the slope (GRS score) is not as significant** compared to the other feature/slope, bee group. In other words, we can see that when the bee group changes/increases (in other words when the type of bee changes), the E-score increases by 0.8648 and when the GRS score increases/changes, the E-score increases by 0.1667. Meaning that bee group has a stronger relationship **(more significant)** to E-score compared to the GRS score variable **(less significant)**. \n",
    "\n",
    "Additionally, when we take a look at the p-value of our slope for GRS,  we can see that it has a p-value greater than 0.05. This further shows that **GRS score is not a significant factor** in affecting E-score. However, if we take a look at the p-value for our slope (group), we can see that it has a value that is under 0.05, showing that **group is a significant variable**.\n",
    "\n",
    "This further addresses our research question and also shows that being in different bee groups (being a different bee type) has an effect on E-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31934d2-0443-4871-9979-9220ed8ad588",
   "metadata": {},
   "source": [
    "## **Comparision of the two 2-variable models using two model metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e2bd0-74f6-4bc8-94d9-b7cfab43953c",
   "metadata": {},
   "source": [
    "**Comparison of R-Square Values:**\n",
    "\n",
    "**Model 1:** Has a R-Square of 0.112\n",
    "\n",
    "**Model 2:** Has a R-Square of 0.048\n",
    "\n",
    "**Comparison of log-likelihood Values:**\n",
    "\n",
    "**Model 1:** Has a log-likelihood of -357.39\n",
    "\n",
    "**Model 2:** Has a log-likelihood of -362.83\n",
    "\n",
    "Upon comparing the R-Square and log-likelihood values between our two, two variable models, we can see that model 1 is a better predictor for our target feature (E-Score). As mentioned earlier, a higher R-square value means that it is a better model, and we can see that model 1 has a higher R-squared value of 0.112 compared to model 2 with a R-squared value of 0.048. When we compared the log-likelihood values, a log-likelihood value that is closer to 0 is the better model. When the log-likelihood values were compared between the two models, we can see that model 1 had a log-likelihood value of -357.39, which is closer to 0 compared to model 2 with a log-likelihood value of -362.83. Based on the comparisons, model 1 is the better model for predicting our target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcebd15-46b9-47d7-903a-9adfccb961bb",
   "metadata": {},
   "source": [
    "## <u>Research Question 2: Was the GRS score affected more by exposure to flupyradifurone or being in different bee groups?</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065f970-3d8f-43e2-befb-943a8c8ab29e",
   "metadata": {},
   "source": [
    "For the purpose of this research question my target feature is GRS score, which is the same target feature for one of my questions in part 3 of my project. GRS score relates to the taste response of bees, and essentially I wanted to see what variable had more of an effect on the taste response. So, creating a linear model for this feature would help answer my research question because it can help me see which feature had a higher impact on GRS score. In other words, which feature had the best correlation to GRS score. \n",
    "\n",
    "**Hypothesis:** Exposure to flupyradifurone has a higher effect on GRS score compared to being in different bee groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bbde6-302f-422b-8777-af59be10c467",
   "metadata": {},
   "source": [
    "### Model 1: GRS score and flupyradifurone exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834b86f-9013-44cf-a68c-c2fdaf5bf4cc",
   "metadata": {},
   "source": [
    "With this first model, I wanted to see how exposure to flupyradifurone affected the GRS score of bees. With this model I am basically trying to ask if flupyradifurone exposure has an effect on GRS score. This model would be able to tell me if flupyradifurone exposure had a positive or negative relationship to GRS score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e56f35d-38e2-4603-a530-cb69d1d9e043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>GRS score</td>    <th>  R-squared:         </th> <td>   0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   92.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>2.07e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:28</td>     <th>  Log-Likelihood:    </th> <td> -716.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   326</td>      <th>  AIC:               </th> <td>   1436.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   324</td>      <th>  BIC:               </th> <td>   1444.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment code</th> <td>    1.4100</td> <td>    0.147</td> <td>    9.612</td> <td> 0.000</td> <td>    1.121</td> <td>    1.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>    0.7656</td> <td>    0.312</td> <td>    2.451</td> <td> 0.015</td> <td>    0.151</td> <td>    1.380</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.631</td> <th>  Durbin-Watson:     </th> <td>   2.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>   6.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.151</td> <th>  Prob(JB):          </th> <td>  0.0389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.378</td> <th>  Cond. No.          </th> <td>    6.56</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              GRS score   R-squared:                       0.222\n",
       "Model:                            OLS   Adj. R-squared:                  0.219\n",
       "Method:                 Least Squares   F-statistic:                     92.40\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):           2.07e-19\n",
       "Time:                        15:44:28   Log-Likelihood:                -716.14\n",
       "No. Observations:                 326   AIC:                             1436.\n",
       "Df Residuals:                     324   BIC:                             1444.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "treatment code     1.4100      0.147      9.612      0.000       1.121       1.699\n",
       "const              0.7656      0.312      2.451      0.015       0.151       1.380\n",
       "==============================================================================\n",
       "Omnibus:                       11.631   Durbin-Watson:                   2.119\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):                6.495\n",
       "Skew:                           0.151   Prob(JB):                       0.0389\n",
       "Kurtosis:                       2.378   Cond. No.                         6.56\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code sets our treatment code column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if treatment code was seen as a string.\n",
    "bee_marker = (forager_bee_no0['treatment code']).astype(int)\n",
    "# This part of the code creates a new dataframe with our GRS score and the Treatment code. This new dataframe is stored into a variable called to_model\n",
    "to_model = pd.DataFrame({\"GRS score\":forager_bee_no0['GRS'],\n",
    "                         \"treatment code\": bee_marker})\n",
    "\n",
    "# This part of the code removes any null values from the GRS column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['GRS score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the GRS score column of our dataframe to_model into the variable y\n",
    "y = to_model[\"GRS score\"]\n",
    "# This part of the code sets the treatment code, and const column of our dataframe to_model into the variable X\n",
    "X = to_model.loc[:,(\"treatment code\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker\n",
    "model_marker = sm.OLS(y, X).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48614024-0a72-44bc-ab44-9e01631f642e",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5154e-b5bc-48e4-8228-3b5b499fdfbb",
   "metadata": {},
   "source": [
    "Based on the model, we can see that the slope of our model is 1.4100 and our intercept is 0.7656. Since our slope is positive, it means that there is a positive relationship between GRS score and flupyradifurone exposure. \n",
    "\n",
    "To determine the certainty of our parameters, I took a look at the confidence interval of our model. We can see that the confidence intervals of our slope (treatment code) are both positive numbers, this means that our data will be between these numbers. Additionally when we take a look at the confidence interval for our intercept (const), it also shows two positive numbers, meaning that our intercept will be between these two positive numbers because our confidence intervals are positive, further supporting that our parameters are indeed positive. Due to this, we can be **certain** that our parameters are positive. \n",
    "\n",
    "To further see if this parameter is accurate, we can take a look at the p-value of both parameters. The p-value of our slope was 0 and the p value of our intercept was 0.015. Since both of our p-value is under our alpha (0.05) we can reject our null hypothesis, further confirming that there is a relationship between GRS score and flupyradifurone exposure. Due to this we can be **certain** about our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ad6f3-6eac-4b92-860a-b78b4b1f6a6c",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201fec70-1d4c-414c-b9be-77f82f623f4b",
   "metadata": {},
   "source": [
    "Based on the results, we can conclude that as treatment code increases (in this case the highest exposure to the chemical is treatment code 1, medium exposure is treatment code 2 and the least exposure is treatment code 3), the GRS score of the bees increased. Which shows that GRS score increases by 1.4100 as the treatment code goes up. This shows that GRS score is indeed greatly affected by fluypyradifurone exposure. We can conclude this due to a significant change of 1.4100 in GRS score as flypuradifurone exposure changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9986e23-0765-4793-88e1-fa0f342d2470",
   "metadata": {},
   "source": [
    "### Model 2: GRS score and bee group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bd4a6-e01f-48c2-a037-47a16e992348",
   "metadata": {},
   "source": [
    "With this second model, I wanted to see how being in different bee groups affected the GRS score. With this model, I am trying to ask if GRS score is affected by being in different bee groups. This model would be able to address my hypothesis as it can tell me if being in different bee groups (or being a different bee type) had a positive or negative relationship to GRS score. \n",
    "\n",
    "**As stated previously, using bee group would make sense for this model because when we increase our bee group we are essentially changing our bee type. This scientific paper categorizes these bees into different groups based on what type of forager bee it is. These groups do not consists of the same type of bee. These groups are actually different, containing different types of bees (not the same ones). So by changing our bee group (from group 1 to group 2) we can see if one of these two groups performed better than the other in terms of their GRS score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbf0024-bb3f-4d69-90a5-89e1bfd96a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>GRS score</td>    <th>  R-squared:         </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.4578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 10 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.499</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:44:28</td>     <th>  Log-Likelihood:    </th> <td> -756.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   326</td>      <th>  AIC:               </th> <td>   1518.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   324</td>      <th>  BIC:               </th> <td>   1525.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group</th> <td>   -0.1860</td> <td>    0.275</td> <td>   -0.677</td> <td> 0.499</td> <td>   -0.727</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.8053</td> <td>    0.424</td> <td>    8.973</td> <td> 0.000</td> <td>    2.971</td> <td>    4.640</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>267.624</td> <th>  Durbin-Watson:     </th> <td>   2.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  21.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.002</td>  <th>  Prob(JB):          </th> <td>2.23e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.744</td>  <th>  Cond. No.          </th> <td>    6.63</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              GRS score   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.002\n",
       "Method:                 Least Squares   F-statistic:                    0.4578\n",
       "Date:                Sat, 10 Dec 2022   Prob (F-statistic):              0.499\n",
       "Time:                        15:44:28   Log-Likelihood:                -756.81\n",
       "No. Observations:                 326   AIC:                             1518.\n",
       "Df Residuals:                     324   BIC:                             1525.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "group         -0.1860      0.275     -0.677      0.499      -0.727       0.355\n",
       "const          3.8053      0.424      8.973      0.000       2.971       4.640\n",
       "==============================================================================\n",
       "Omnibus:                      267.624   Durbin-Watson:                   2.071\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.419\n",
       "Skew:                           0.002   Prob(JB):                     2.23e-05\n",
       "Kurtosis:                       1.744   Cond. No.                         6.63\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part of the code sets our group column in our dataframe forager_bee_no0 as a int. This is to ensure that when we model this data,\n",
    "# everything we use is an integer and not a string. This is just as a pre-caution just incase if the group column was seen as a string.\n",
    "bee_marker = (forager_bee_no0['group']).astype(int)\n",
    "# This part of the code creates a new dataframe with our GRS score and the group. This new dataframe is stored into a variable called to_model\n",
    "to_model = pd.DataFrame({\"GRS score\":forager_bee_no0['GRS'],\n",
    "                         \"group\": bee_marker})\n",
    "\n",
    "# This part of the code removes any null values from the GRS column. This new dataframe is stored into a variable called to_model again\n",
    "to_model = to_model[~pd.isnull(to_model['GRS score'])]\n",
    "# This part of the code adds a constant column into our dataframe to_model. This information is stored into our variable called to_model.\n",
    "to_model = sm.add_constant(to_model)\n",
    "# This part of the code sets the GRS column of our dataframe to_model into the variable y\n",
    "y = to_model[\"GRS score\"]\n",
    "# This part of the code sets the group, and const column of our dataframe to_model into the variable X\n",
    "X = to_model.loc[:,(\"group\",\"const\")]\n",
    "# This part of the code models our data, and stores the information into a variable called model_marker\n",
    "model_marker = sm.OLS(y, X).fit()\n",
    "# This part of the code displays the numerical values of our model\n",
    "model_marker.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911761b6-cf92-46cc-9b50-77e3dff4522b",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model and its parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eee09b-e4c9-4a43-af4f-5337cf8d0f21",
   "metadata": {},
   "source": [
    "Based on the results of the model, we can see that our slope is negative with a value of -0.1860 and a intercept of 3.8053. Since our slope is negative, it means that there is a negative relationship between bee group and GRS score. \n",
    "\n",
    "To confirm the certainty of our parameters, I took a look at the confidence interval of our model. When we take a look at the confidence interval of our model, we can see that our slope (group) had a negative and positive number. The confidence interval for our intercept (const) had both positive number for its confidence interval. Now due to our slope having a positive and negative number for its confidence interval, we can't be certain about our negative slope because we have a positive number in our confidence interval.\n",
    "\n",
    "To further determine the certainty of our parameters we can take a look at the p-value. The p-value of our slope  is 0.499 and the p-value of our intercept is 0. Since we have a p-value that is greater than 0.05 for our slope, we fail to reject our null hypothesis, further confirming that GRS score may not be particularly affected by different bee groups. Due to this we **can't be certain** about our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c074f50-efbe-4503-9791-73143e4714ec",
   "metadata": {},
   "source": [
    "## **Interpreting the results of the model in everyday language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f817de2-6b00-4d44-ac1d-0337767952f9",
   "metadata": {},
   "source": [
    "However, based on the overall results, it can be assumed/concluded that as the bee group changes (increases) the GRS score decreases by 0.1860, meaning that bee group may have an effect on GRS score. In other words, as the bee type changes, (from pollen (group 1) to nectar forager bees (group 2)) we can see a decrease in GRS score by 0.1860. This means that between these two different types of forager bee, one type of forager bee may perform better than others in terms of their GRS score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff276c3-2f84-485a-ab36-d52d2130fdd1",
   "metadata": {},
   "source": [
    "## **Comparision of the two single variable models using two model metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58269b04-095d-47e1-9d45-5eee1de39ddf",
   "metadata": {},
   "source": [
    "**Comparison of R-Square Values:**\n",
    "\n",
    "**Model 1:** Has a R-Square value of 0.222\n",
    "\n",
    "**Model 2:** Has a R-Square value of 0.001\n",
    "\n",
    "**Comparison of log-likelihood Values:**\n",
    "\n",
    "**Model 1:** Has a R-Square value of -716.14\n",
    "\n",
    "**Model 2:** Has a R-Square value of -756.81\n",
    "\n",
    "Upon comparison of the R-square and log-likelihood values between our two models, model 1 appears to be the better model. As mentioned before, the higher the R-Square value, the better the model (the better the model fits our data), and when we compare the R-squared values we can see that model 1 had a higher R-squared compared to model 2. Additionally, when we compare the log-likelihood values, a value that is closer to 0 is a better model. So when we once again compare the log-lileihood values of the two models, we can see that model 1 has a log-likelihood value that is closer to 0. Since model 1 had a higher R-squared value and a log-likelihood closer to 0, this means that model 1 is a better predictor of our target feature (GRS score). Which supports my hypothesis that flupyradifurone exposure has a higher effect on GRS score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
